The World Health Organization has made “internet gaming” a diagnosable disorder. But many experts aren’t even sure it exists.

The World Health Organization last month added “internet gaming disorder” to its manual of psychiatric diagnoses, and the reaction was, shall we say, muted.

At a time when millions of grown adults exchange one-liners with Siri or Alexa, the diagnosis seems years overdue, doesn’t it?

Put down your phone and look around: If half the people you see walking down the street or riding the bus with you are face-deep in a small screen, then it’s not a wild leap to think that some percentage of us, particularly those younger and male, have fallen hard for “Fortnite” or “League of Legends” or “World of Warcraft” and cannot get up, except to fetch the occasional bowl of Lucky Charms.

They’re stuck. They sleep with their heads on keyboards. They could use a friend of the breathing, let’s-go-to-the-park variety. They could use some help.

Yet embracing I.G.D., as it’s known, as a new mental health disorder has its own perils. Many psychologists are skeptical that it exists at all as a stand-alone problem. The diagnostic criteria are still fuzzy, and the potential for overdiagnosis is enormous.

[Like the Science Times page on Facebook. | Sign up for the Science Times newsletter.]

I.G.D. is a case study in what happens when researchers become convinced that a bad habit has become something different: a disorder. The studies pile up and the notion takes on a life of its own —  one that may or may not be persuasive to putative “patients.”

“The question is, what’s the difference between a bad habit and a disorder, and where do you draw that line,” said Scott Lilienfeld, a professor of psychology at Emory University.

“Some, like me, believe there’s often no reliable way to do that. Others disagree. The point is, you need to be very careful in doing so” for people who need help to buy in.

The W.H.O.’s definition of gaming disorder is a mouthful:

A pattern of gaming behavior characterized by impaired control over gaming, increasing priority given to gaming over other activities to the extent that gaming takes precedence over other interests and daily activities, and continuation or escalation of gaming despite the occurrence of negative consequences.

As a diagnosis, it’s a potential blockbuster. Estimates of its prevalence — up to 9 percent of all gamers — mean that tens of millions of mostly young people worldwide may now be said to have a mental disorder.

Some of them surely do, whatever its underlying dynamics.

“The kids I see truly have a problem, and it has disastrous effects on many parts of their lives — school performance, social life, their moods,” said Dr. Clifford Sussman, a psychiatrist in Washington who treats compulsive gaming with psychotherapy.

“It doesn’t much matter what you call it, the point is to give them tools” to control the habit, he added, and better integrate it into their lives.

Many other psychiatrists agree and say they have treated the compulsion successfully. But the American Psychological Association, among other groups, takes exception to the diagnosis.

The association argues that the definition remains too vague, and that mood problems may in fact precede excessive gaming, not vice versa. The new label reflects a “moral panic,” the critics say — an unfounded fear of new technology that years ago had parents and some experts finger-wagging about the mentally corrosive effects of TV, and before that, radio.

“There’s a kernel of truth in what the partisans are saying,” said Christopher Ferguson, a psychologist at Stetson University who has been a skeptic of the many ills attributed to gaming. “There’s something to this, although we really don’t know enough to understand it entirely.”

Parts of the published science thus far, he said, have not been reassuring. Take, for example, the search for a “signature” of the disorder in the brain.

In one recent study, a group of scientists in China and Europe asked 38 people they identified as having I.G.D. put their heads inside an MRI scanner.

Compared to peers who had less compulsive gaming habits, the I.G.D. group “showed significantly decreased cortical thickness in the left lateral orbitofrontal cortex, inferior parietal lobule, bilateral cuneus, precentral gyrus, and right middle temporal gyrus,” the researchers announced.  
Another report, also using brain imaging, concluded that people with I.G.D. had “decreased connectivity between the left amygdala and left middle frontal and precentral gyrus.”

That’s a lot of fancy-sounding brain regions. But the conclusions are all virtually meaningless, since no one knows much about how those regions interact, or why one gamer’s bilateral cuneus happens to be thicker than another’s.

Another recent study focused on treatment: not just any treatment but bupropion, an antidepressant often used in smoking cessation.

The study found that, after 12 weeks, “depressive symptoms, attention and impulsivity improved,” and so did scores, for some, on something called the Young Internet Addiction Scale.  
No word on whether participants in the study actually learned to manage their gaming habits in a lasting way.

“Once you decide there’s a disorder, you start looking for it in people’s brains and trying to knock it out, like you would a brain tumor,” Dr. Lilienfeld said.

But of course there is no tumor in this case.

Finally, yet another recent study hinted that one way to break the gaming trance is to put screen junkies on horseback.

After seven days of “equine-assisted activities and therapies,” a group of adolescents diagnosed with I.G.D. showed improvement in “avoidance and anxiety scores,” this study concluded.

Horse riding, usually with a therapist-guide riding alongside, giving instruction and encouragement, has shown some benefit for people with autism, traumatic brain injury and post-traumatic stress.

Now...gamers.

Whether W.H.O.’s inclusion of compulsive gaming eventually leads to better research, or to standardized treatments that reliably change behavior, is an open question.

But for now it would be hard to blame anyone with a serious joystick jones for balking at the prospect of a “disorder.”

A bad habit may be bad. But at least fixing it doesn’t involve brain scans, antidepressant pills or clinging for dear life to some cantering Cheyenne or Misty.

The digital horses are a lot safer to ride, after all. And you get to carry a sword.

Benedict Carey has been a science reporter for The Times since 2004. He has also written three books, “How We Learn” about the cognitive science of learning; “Poison Most Vial” and “Island of the Unknowns,” science mysteries for middle schoolers. 